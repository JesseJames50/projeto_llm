{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16PYzD_ZX2NOc2xobiE7qs-NI1kZudaJc",
      "authorship_tag": "ABX9TyMschasKr8izy4RmntO64tt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JesseJames50/projeto_llm/blob/main/sistema_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbW6MdMjc9Lt"
      },
      "outputs": [],
      "source": [
        "!pip install qdrant-client openai langchain PyPDF2\n",
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --upgrade"
      ],
      "metadata": {
        "id": "zI6XxUNogJ0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "n8rwISUadYrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5pPJI4jsddqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import PointStruct, VectorParams, Distance\n",
        "from uuid import uuid4\n",
        "from datetime import datetime\n",
        "import os\n",
        "import PyPDF2\n",
        "from langchain import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "# Carrega as variáveis de ambiente do arquivo .env\n",
        "load_dotenv()\n",
        "apenai_key = os.getenv('OPENAI_API_KEY')\n",
        "qdrant_key = os.getenv('QDRANT_API_KEY')\n",
        "\n",
        "# Configure a API key da OpenAI\n",
        "client = OpenAI(\n",
        "  api_key= apenai_key,  # this is also the default, it can be omitted\n",
        ")\n",
        "\n",
        "# Nome da coleção no Qdrant\n",
        "collection_name = 'documents_collection'\n",
        "\n",
        "# Configurar Qdrant\n",
        "client_Qdrant = QdrantClient(\n",
        "    url=\"https://20344d73-d460-4ad6-972f-7626b4af36bf.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=qdrant_key\n",
        ")\n",
        "\n",
        "# Criar coleção no Qdrant\n",
        "# Verificar se a coleção existe, caso contrário, criar\n",
        "if not client_Qdrant.collection_exists(collection_name):\n",
        "    client_Qdrant.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "6oqAFh2_dDSJ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Extrair Texto dos PDFs"
      ],
      "metadata": {
        "id": "-N5ZfVvvdwOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            text += reader.pages[page_num].extract_text()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "qr9LIRkedDcx"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Dividir o Texto em Partes Menores"
      ],
      "metadata": {
        "id": "freLnsTlPsLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chunks(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "oHn5w8MoPsdL"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Identificar o Assunto com Langchain"
      ],
      "metadata": {
        "id": "Q5rpqweHd0vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o template do prompt para identificar o assunto\n",
        "prompt_template_subject = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Identifique o assunto do seguinte texto:\\n\\n{text}\\n\\nAssunto:\"\n",
        ")\n",
        "\n",
        "# Função para identificar o assunto de um chunk\n",
        "def identify_subject(text):\n",
        "    prompt = prompt_template_subject.format(text=text)\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "    subject = response.choices[0].message.content\n",
        "    return subject.strip()\n",
        "\n",
        "# Função para identificar o assunto de uma amostra de chunks\n",
        "def identify_subjects(text, num_chunks=5):\n",
        "    chunks = get_chunks(text)\n",
        "    sample_chunks = chunks[:num_chunks] + chunks[-num_chunks:]\n",
        "    subjects = [identify_subject(chunk) for chunk in sample_chunks]\n",
        "    # Usar o assunto mais frequente ou combinar os assuntos\n",
        "    final_subject = max(set(subjects), key=subjects.count)\n",
        "    return final_subject\n"
      ],
      "metadata": {
        "id": "lp8PhRabdDjP"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Gerar Embeddings com OpenAI"
      ],
      "metadata": {
        "id": "MNKv9_CteXFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(\n",
        "        input=text,\n",
        "        model=model\n",
        "    )\n",
        "    return response.data[0].embedding"
      ],
      "metadata": {
        "id": "DCf6NYBTeXTx"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inserção dos Dados no Qdrant"
      ],
      "metadata": {
        "id": "mydPn-YteE9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_documents_into_qdrant(directory):\n",
        "    current_date = datetime.now().isoformat()\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(directory, filename)\n",
        "            text = extract_text_from_pdf(pdf_path)\n",
        "            subject = identify_subjects(text)\n",
        "            chunks = get_chunks(text)\n",
        "            embeddings = [generate_embeddings(chunk) for chunk in chunks]\n",
        "\n",
        "            for chunk, embedding in zip(chunks, embeddings):\n",
        "                uid = str(uuid4())\n",
        "                document = {\n",
        "                    \"id\": uid,\n",
        "                    \"vector\": embedding,\n",
        "                    \"payload\": {\n",
        "                        \"assunto\": subject,\n",
        "                        \"text\": chunk,\n",
        "                        \"datainclusao\": current_date,\n",
        "                        \"data_modificacao\": current_date\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                point = PointStruct(id=document[\"id\"], vector=document[\"vector\"], payload=document[\"payload\"])\n",
        "                client_Qdrant.upsert(\n",
        "                    collection_name=\"documents_collection\",\n",
        "                    points=[point],\n",
        "                )\n",
        "\n",
        "# Insira os documentos da pasta \"documents\"\n",
        "insert_documents_into_qdrant(\"/content/data\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qczTQZdKdDrZ"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Buscar por Assunto"
      ],
      "metadata": {
        "id": "Y3MRLKVYfBh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_by_subject(subject, client, collection_name, top_k=5):\n",
        "    query_vector = generate_embeddings(subject)\n",
        "\n",
        "    search_result = client.search(\n",
        "        collection_name=collection_name,\n",
        "        query_vector=query_vector,\n",
        "        limit=top_k\n",
        "    )\n",
        "    return search_result\n"
      ],
      "metadata": {
        "id": "WZL7jsG1dDzR"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo de busca por assunto"
      ],
      "metadata": {
        "id": "jq9d4ynhfNMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de busca por assunto\n",
        "subject_query = \"Faça um resumo sobre o que é a escola austríaca.\"\n",
        "results = search_by_subject(subject_query, client_Qdrant, \"documents_collection\")\n",
        "\n",
        "for result in results:\n",
        "    print(result.payload[\"text\"])"
      ],
      "metadata": {
        "id": "Nwwk76LufNhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}